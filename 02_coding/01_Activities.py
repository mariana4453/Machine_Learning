import math, copy
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import time


path = "./01_data/Activities.csv"
df_activities = pd.read_csv(path)

columns_rename = {'Ğ¢Ğ¸Ğ¿ Ğ·Ğ°Ğ½ÑÑ‚Ğ¸Ñ': 'activity',
                  'Ğ”Ğ°Ñ‚Ğ°': 'date',
                  'ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ': 'name',
                  'Ğ Ğ°ÑÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ': 'Distance',
                  'ĞšĞ°Ğ»Ğ¾Ñ€Ğ¸Ğ¸': 'Calories',
                  'Ğ’Ñ€ĞµĞ¼Ñ': 'Time_of_activity',
                  'Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ Ğ§ĞŸ': 'Average_pulse',
                  'ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ§ĞŸ': 'Maximum_pulse',
                  'Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ° ÑˆĞ°Ğ³Ğ°': 'Average_pace',
                  'ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ° ÑˆĞ°Ğ³Ğ°': 'Maximum_pace',
                  'Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹ Ñ‚ĞµĞ¼Ğ¿': 'Average_speed',
                  'Ğ›ÑƒÑ‡ÑˆĞ¸Ğ¹ Ñ‚ĞµĞ¼Ğ¿': 'Best_speed',
                  'ĞĞ±Ñ‰Ğ¸Ğ¹ Ğ¿Ğ¾Ğ´ÑŠĞµĞ¼': 'uphill',
                  'ĞĞ±Ñ‰Ğ¸Ğ¹ ÑĞ¿ÑƒÑĞº': 'downhill',
                  'Training Stress ScoreÂ®': 'training_stress_score',
                  'Ğ’Ñ€ĞµĞ¼Ñ Ğ»ÑƒÑ‡ÑˆĞµĞ³Ğ¾ ĞºÑ€ÑƒĞ³Ğ°': 'Best_lap_time',
                  'ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ĞºÑ€ÑƒĞ³Ğ¾Ğ²': 'laps'
                  }
df_activities = df_activities.rename(columns=columns_rename)
df_activities = df_activities[['activity', 'date', 'name', 'Distance', 'Calories', 'Time_of_activity',
                               'Average_pulse', 'Maximum_pulse', 'Average_pace', 'Maximum_pace', 'Average_speed',
                               'Best_speed', 'uphill', 'downhill', 'training_stress_score', 'Best_lap_time', 'laps']]


# trying Linear regression - one variable
df_sample = df_activities[['Distance', 'laps']]

x_train = df_sample['Distance']
y_train = df_sample['laps']

# Model function: ğ‘“ ğ‘¤,ğ‘( ğ‘¥(ğ‘–) ) = ğ‘¤ğ‘¥(ğ‘–)+ğ‘
# trying:
# for  ğ‘¥(0),f_wb = w * x[0] + b
w = 1
b = 1


def compute_model_output(x, w, b):
    m = x.shape[0]
    f_wb = np.zeros(m)
    for i in range(m):
        f_wb[i] = w * x[i] + b
    return f_wb


# plotting the result
# tmp_f_wb = compute_model_output(x_train, w, b)
#
# # prediction
# plt.plot(x_train, tmp_f_wb, c='blue', label='Prediction')
#
# # Plot the data points
# plt.scatter(x_train, y_train, marker='x', c='r', label='Actual Values')
#
# # Set the title
# plt.title("Housing Prices")
#
# # Set the y-axis label
# plt.ylabel('Price (in 1000s of dollars)')
#
# # Set the x-axis label
# plt.xlabel('Size (1000 sqft)')
# plt.legend()
# plt.show()


# cost function - the lesser the cost the better it is
# ğ½ (ğ‘¤,ğ‘) = 1/2ğ‘š âˆ‘ (ğ‘“ğ‘¤,ğ‘ (ğ‘¥(ğ‘–)) âˆ’ ğ‘¦(ğ‘–) ) ^ 2

# w = np.arange(-10, 10, 1)

def compute_cost(x, y, w, b):
    # number of training examples
    m = x.shape[0]

    cost_sum = 0
    for i in range(m):
        f_wb = w * x[i] + b
        cost = (f_wb - y[i]) ** 2
        cost_sum = cost_sum + cost
    total_cost = (1 / (2 * m)) * cost_sum

    return total_cost


# total_cost_list = []
# for i in range(w.shape[0]):
#     cost = compute_cost(x_train, y_train, i, b)
#     total_cost_list.append(cost)
#
# x = w
# y = total_cost_list
#
# plt.plot(x, y)
# plt.show()